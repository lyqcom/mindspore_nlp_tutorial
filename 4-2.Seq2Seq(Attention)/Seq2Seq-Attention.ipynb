{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a0766e3-3816-4303-af74-2dfc50ba5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as mnp\n",
    "import matplotlib.pyplot as plt\n",
    "from mindspore import ms_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f4888e33-7ea9-437a-be7d-3151891ed97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "\n",
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return mindspore.Tensor(input_batch), mindspore.Tensor(output_batch), \\\n",
    "        mindspore.Tensor(target_batch, mindspore.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0242cf52-c02a-4670-ab34-e376cb140744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Dense(n_hidden, n_hidden)\n",
    "        self.out = nn.Dense(n_hidden * 2, n_class)\n",
    "\n",
    "    def construct(self, enc_inputs, dec_inputs):\n",
    "        enc_inputs = enc_inputs.swapaxes(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.swapaxes(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = []\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].expand_dims(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = ops.matmul(attn_weights, enc_outputs.swapaxes(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            out = self.out(ops.concat((dec_output, context), 1))\n",
    "            model.append(out)\n",
    "        \n",
    "        model = ops.stack(model)\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.swapaxes(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = ops.zeros(n_step, mindspore.float32)  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return ops.Softmax()(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return mnp.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar valuek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad18877e-322a-42af-97bf-f13b561760d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step = 5 # number of cells(= number of Step)\n",
    "n_hidden = 128 # number of hidden units in one cell\n",
    "\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2ef50a8e-f4c0-44c8-82cd-750cc7ba3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(258161:139710830719232,MainProcess):2022-08-12-21:41:32.952.304 [mindspore/nn/layer/rnns.py:392] dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "[WARNING] ME(258161:139710830719232,MainProcess):2022-08-12-21:41:32.961.000 [mindspore/nn/layer/rnns.py:392] dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n"
     ]
    }
   ],
   "source": [
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "612ce97a-4fc3-4953-b641-bcd9f800f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch, target_batch = make_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "002ae643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(enc_input, dec_input, target):\n",
    "    output, attn = model(enc_input, dec_input)\n",
    "    loss = criterion(output, target.squeeze(0))\n",
    "    return loss, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47904591",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = ops.value_and_grad(forward, None, optimizer.parameters, has_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "843167f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ms_function\n",
    "def train_step(enc_input, dec_input, target):\n",
    "    (loss, _), grads = grad_fn(enc_input, dec_input, target)\n",
    "    optimizer(grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5f192fcb-4bad-4b97-9611-e24c8a0d966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000808\n",
      "Epoch: 0800 cost = 0.000266\n",
      "Epoch: 1200 cost = 0.000135\n",
      "Epoch: 1600 cost = 0.000080\n",
      "Epoch: 2000 cost = 0.000053\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(2000):\n",
    "    loss = train_step(input_batch, output_batch, target_batch)\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa47c242-103d-471d-983d-2480830b7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = mindspore.Tensor(test_batch)\n",
    "predict, trained_attn = model(input_batch, test_batch)\n",
    "predict = predict.argmax(1)\n",
    "print(sentences[0], '->', [number_dict[int(n.asnumpy())] for n in predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc60f4c8-461b-4640-97f2-b50fb6da5f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lvyufeng/miniconda3/envs/ms1.8/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \"\"\"\n",
      "/home/lvyufeng/miniconda3/envs/ms1.8/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow([attn.asnumpy() for attn in trained_attn], cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ms1.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd0943702584cdb580f8947884f31a9fb49482f77f8c89ed6532de3aa180e7ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
